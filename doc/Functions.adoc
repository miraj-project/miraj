functions considered harmful
============================

abstract: in practical computing, the standard mathematical notion of
function gets in the way of a more general notion of computation based
on the core concepts of interaction and behavior.  Milner: "Every
basic model [of computation] rests upon a small number of primitive
notions; the pi-calculus [of communicating and mobile systems] rests
upon the primitive notion of _interaction_, just as Turing machines
and register machines rest upon the notion of reading and writing of a
storage medium, and just as recursive equations and the lambda
calculus rest upon mathematical functions." (p. 77) In this document I
argue that in practical computing the notion of function (esp. "pure"
function) is over-emphasized, especially wrt functional languages, and
should be replaced (or at least complemented) by a notion of
_co-function_ based on Milner's (and other thing/co-thing) work.
Mathematical functions are fine in theoretical _models_ of
computation, but in real-world computational systems there are no
genuine functions, only approximations of functions, and
non-functional operations probably outnumber them.  I discuss a number
of popular myths regarding functions in programming (the Myth of Pure
Functions, the Myth of Functional IO) I argue further that a notion of
co-function based on an interactional structure pairing activation and
observation is actually more fundamental than the notion of function;
physical functions (practical approximations to mathematical
functions) can be explicated in terms of co-functions, but not
vice-versa.  The practical implications of this shift are significant;
a clean and simple notion of co-function leads to more transparent and
simpler code in many situations, especially those involving unreliable
communication channels (networking, serial ports, etc.)  Finally, I
give some examples in Clojure, whose core.async can be viewed as a
(partial) practical implication of the concepts discussed here.

There are no functions in real-world computation.  With a little
thought this should be obvious: real-world computers are finite, so it
is not possible even in principle for them to compute infinite
functions.  They best we can do with them is _approximate_ genuine,
mathematical functions.  Well, _computable_ mathematical functions, of
course.

Infinity is not the only problem.  Functions computed by real-world
machines - we'll call them _physical_ functions, in contrast to
_mathematical_ functions - are always, ineluctably, unreliable.  That
is, the physical computation itself will always be unreliable, even if
the mathematical function it models is not.  Machines have defects;
they break; they can be used incorrectly.  We can never be 100%
certain that a given machine will compute correctly, simply because it
is not possible to build a perfect machine; again, the best we can do
is approximate a perfect machine, by engineering one whose correct
functioning is very likely.

Even if we have - as we do - very reliable machines, program
  translation is another source of uncertainty.  In practice program
  translation - compilation - is an essential step in machine building
  (programming).  It is inconceivable that the complex software we use
  today could be built without it.  But like physical machines,
  compilers can never be 100% reliable.  We can try to formally prove
  their correctness, but this just moves the problem: the tools we use
  to prove the correctness of a compiler must themselves be proven
  correct, so we inevitably enter an infinite regress.  Again the best
  we can do is approximate proof by minimizing uncertainty.

It follows that all physical functions -- the "functions" we define
and use in programming languages -- are in fact black box devices:
function-like, perhaps, but ultimately a very different kind of beast.
This is true even if their source code is available for inspection and
verification, for the reasons adduced above.  If we do have the source
code, we can greatly reduce our uncertainty by inspecting it and
convincing ourselves it is correct, but we can never eliminate it
altogether.  If we do not have the source code then the only means at
our disposal for reducing uncertainty is _observation_.
(Documentation?  Faugh!)  This applies not only to closed-source
libraries but also to devices that may be represented in software,
such as serial ports, IO peripherals, sensors we may try to read, etc.
Lacking direct evidence of their meaning (via inspection of their
internals) and therefore deductive proof of their correctness, we have
no choice but to rely on inductive reasoning: use them, observer the
results, and drawn inferences as to their meaning and use.  The notion
of behavior observation is the critical point of contrast with the
concept of function.  As will become clear in what follows, it allows
us to subsume the notion of a physical function under a more general
concept that also covers interactivity and thus many of the critical
real-world problems associated with distributed, parallel, concurrent,
etc. computing.

A third problem - call it the Myth of the Pure Function - is that
physical functions _always_ have side effects.  At the very least,
they consume time, space, and energy.

That the notion of a function in real-world computing is a fiction
should be obvious, perhaps to the point of triviality; but I argue
that it is in fact harmful, insofar as it distracts us from another,
better model of real-world computing.

A co-function is a black box.  Its internal state and computational
processes are completely hidden; we can only do two things with it:
_activate_ it, and _observe_ it.

A (physical) function can be viewed as a co-function whose associated
algorithm (implementation) and activate/observe mechanisms are
reliable.

To see this, think about what happens when we "call" a function in a
programming language.

[source,clojure]
----
(defn f [n] (* 2 n))
(def result (f 2))   ;; => 4 bound to `result`
----

This form is intuitive enough, but it leaves several critical bits of
logic implicit.  One is the _application_ of f to its argument a;
another the _assignment_ (or binding, if you prefer) of the result of
the application to the symbol `result`.  We can use pseudo-code to
make these explicit:

[source,clojure]
----
;; infix notation:
(def result bind (apply f a))
;; prefix notation
;; bind binds the value of its second arg to its first, then returns the first
(def (bind result (apply f a)))
----

Readers familiar with core.async will recognize the `<!` symbol; the
choice is intentional for reasons that will become evident, but here
the symbol should _not_ be interpreted as `core.async/<!`.

As an aside: of course, this does not cleanse our form of implicit
meanings; `bind` and `apply` must themselves be "applied", and the
operators that carry out that second level of application must
themselves be applied at a third level, and so on ad infinitum.  There
is no way even in principle to make the semantics of such a form 100%
explicit.  But that's not a problem because for our purposes we just
want to make the first level apply/assign operations explicit.

So this is a little more clear; we've explicitly indicated two of the
operations implicit in function application.  We can think of `bind` and
`apply` as meta-operations made explicit - they represent operations
the runtime environment is reponsible for carrying out.  By making
them explicit we move them from the meta level into our object
language.

A third implicit bit involves the notion of function _evaluation_.
This involves the usual lambda calculus stuff like substituting the
value of `a` for the bound variable `n` in the definition body of f,
and then _reducing_ f to normal form.  But that's not all; to see how
the notion of function relates to that of co-function we need to focus
on how the whole process gets kicked off and how it ends.

Let's start with an obvious observation: the `apply` operator will
have to deliver `a` to `f`; how this actually happens will of course
be implementation-dependent, but conceptually it's something any
`apply` must do.  Symmetrically, `f` must be prepared to "accept" the
value of `a` as its argument before it can proceed with computation.
Let's call this operation as a whole "argument delivery".

*TODO* the critical point is that f must _take_ its argument, not
 passively receive it.  This, to establish isomorphism with the
 action-reaction structure of cooperating concurrent processes.

A final bit of implicit logic concerns `bind`; we'll call this operation
"result delivery".  As in the case of `apply`, we can break down the
operation of `bind` into several conceptual pieces.  First, the `bind`
operator must be prepared to "accept" the value of its (second)
argument - the value of `f` at `a` (the result of evaluating `f` at
`a`) just as `f` must be prepared to accept the value of _its_
argument.  That implies that `bind` is like `f` - function-like, but not
a function, since it has the side-effect of binding its second
argument to its first.  Second, like `apply`, `bind` must make a
delivery.  `apply` delivers its second argument to its first argument;
`bind` delivers _its_ second argument to its first argument.

Note that we here treat the first argument to `bind` as a function.
This is in rather stark contrast to the usual practice of treating as
a symbol to which the result of the computation will be bound.  But
arguably it is more sensible and indeed simpler to treat it as a kind
of nullary, self-evaluating function:

[source,clojure]
----
(defn' result [res] (fn [] res))
----

Here we use `defn'` to indicate that this is just like any other
function definition except that syntactically the defined function is
self-evaluating - you get its value by writing `result` rather than
`(result)`.  (We can think of all constant symbols, like '3', as
predefined functions of this kind).

The advantage of this is that it allows us to do away with the
somewhat mysterious notion of binding the result of a function to a
symbol.  Our "result delivery" operation `bind` is thus a high-level
function just like any other: it applies its first argument to its
second.  Which is exactly what `apply` does.  We've ended up with a
perfectly symmetrical explicitation of function application.  The
beauty of this is that it also matches exactly the structure of
_interactional computation_ involving concurrent sequential processes.

But the problem is that we have just entered into a vicious circle.
We don't want `apply` to "apply" anything; we want to understand what
`apply` means, and we cannot do that but just appealing to the
selfsame concept.  "It applies stuff" is not a good answer to the
question "what does `apply` do?"  Ditto for `bind`.

Key observations:

* body of a defn is a template

* the beginning of wisdom is to always think of fns as devices; we
  don't "apply" devices to input, we configure them (set them up) and then
  activate them

* "apply a function to an arg" is *not* synonymous with "evaluate a function at a value".

** "apply a function to an arg" means _make_ delivery of arg to fn, then _activation_ of fn (qua device)

** "eval a function at a value" is (arguably) what you do _after_ you have taken delivery of an arg and completed alpha conversion of the body template.

** "bind result to sym" means to _observe_ result, _take_ delivery of
   it - which means symmetrically that the fn makes (co-)delivery of result
   to observer, then (co-)activates observer

* activate = make delivery, observe = take delivery

** we want to discard notion of delivery, since it implies messaging,
   which breaks the fiction of quantum entanglement, simultaneous
   activation/observation.  instead: we _use_ arg to activate, and we
   observe arg/result

** to activate a fn using arg is to be observed (but it is the arg
   that is observed); to observe an arg or result is to be activated

** activation must be limited to deliverying arg/result, since we
   cannot act at a distance. so arg delivery presents arg for
   observation; observation is activation (to observe is to be
   affected by the thing observed?)

* traditionally: we call a function, and then get/wait for its result.
  here: we activate function, then observe, waiting for it to activate
  us with result.  a fn return is a (co-)call back to the callee as
  co-fn.  remember fns have entry points; to call a fn is to start it
  at the beginning; for a fn to to co-call a callee is to resume it
  just after the call site

* caller and callee are mutual activators/observers - to activate is to be observered, and to observe is to be activated

* application involves more than just the lambda rules (its not eval, it doesn't handle conversion, reduction, etc.)

* apply may be viewed as overhead - a process that is distinct from the eval process

* ditto for bind

* insofar as bind is a kind of function like apply, same
  considerations apply - it does not mean evaluate

* apply/bind mutually implicated: to apply f to a, f must bind (take) a; to
  bind (f a) (i.e. result of evaluating f at a) to result, `bind` must
  apply (f a) to result, which must bind (take) it.

* in sum: apply and bind are symmetric, same thing in opposite
  directions: put arg to f, which must take it

* summary:  replace apply/bind with make/take

* make/take is symmetric across cooperating processes;

So we're not done.  Both `apply` and `bind` actually involve two parts.
Think of apply as activation of a remote device, and `bind` as
observation of the device's behavior.  Now the device is remote, so a
local `apply` can have no direct effect on it.  The fiction is that
the remote device observes the activation action and responds
appropriately.  So we have activation-observation pairs _between_
processes, not within.  The one side does not observe _its own_
behavior, it observe's its partner's behavior.  To make the fiction of
action-at-a-distance convincing, we need a communication mechanism,
one the one hand, and we need the corresponding activation-observation
operations with respect to that channel.  So if A activates (puts to
the channel), then B observes (takes from the channel).

Translated to function application as a special case, this means that
the function implementation must _take_ its argument, just as a remote
device must take input from the comm channel.  IOW, we can think of
the operation of `apply` as relying on a channel mechanism.

== fictions and myths

* The Myth of Pure Functions

* The Mathematical Fiction

** Function computation is instantaneous, or more accurately,
   atemporal. `(def x (dbl 2))` and `(def x 4)` are synonymous.

** Function application is atomic

** Principle of Semantic Conservation - "pure" functions do not change
   the meaning of the text: the symbols have the same denotation
   "before" and "after" the function call.  This obviously rules out
   "imperative" functions that, for example, change global variable
   values.  But it also rules out coroutines - they change system
   state, because yielding changes the entry point of the routine.
   "Pure" functions do not do this - they only ever have one entry
   point, so the next time they are called they behave the same way.
   Co-routines, by contrast, may have different entry points the next
   time they are called.  (Don't be fooled by special syntax in your
   favorite programming language - for example, "resume" in Lua really
   just means "call", without the sense of "start at the beginning
   (main) entry point of the function".  In other words, the implicit
   assumption is that the function knows where to start, and that may
   be different on different occassions, but the client doesn't have
   to know that - it just calls the function and the function knows
   what to do.

The Mathematical Fiction is that our physical functions are "pure"
mathematical functions.  So a function application expression is _ipso
facto_ equal to - the same as - the value of the expression, that is,
such an expression is by definition the same as its normal (reduced)
form.

A second, related aspect of the Mathematical Fiction is that function
calls are atomic.  Calling a function and "getting" its result amount
to the same thing.

The interactionist model of computation replaces (or perhaps augments)
the Mathematical Fiction with a fiction from physics: quantum
entanglement.  Activation and observation are treated as symmetric
aspects of a single system state; the key fiction is that these
aspects are _not_ linked by any causal mechanism.

So interactionist computation breaks the atomicity of function
appliction into two distinct actions: activation and observation.  It
reifies the caller of the function as well as the function, as
distinct aspects of a single system.  The actual mechanisms involved
in an expression like `let x = sqrt(4)` are glossed over.  This works
just fine for an isolated, offline, non-interactive system, but not
for online, interactive systems.

Howerer, the interactionist model retains the Mathematical Fiction
with respect to function evaluation; but evaluation only occurs on one
side of the entanglement.  It's just the mechanisms involved in
calling a function are receiving are result that are reorganized and
reconceptualized by the interactionist model.

Caveat: activation-observation pairs are on opposite sides of the
entanglement.  So activation of a function by the client is entangled
with the corresponding observation by the server; it is _not_
entangled with observation, by the client, of the result of the
function.  Entanglement of client activation of a function and client
observation of a result is the standard interpretation described
above: the Mathematical Fiction of the atomicity of function
application.  Under the interactionist model, client observation is
entangled, not with client observation, but with server activation.
So "calling" a function under the interactionist model involves a pair
of (oriented) entanglements: one entangles client activation and
server observation, the other entangles server activation and client
observation.


== put and take

put and take are not functions.  they are io ops.

The difference between the interaction-oriented view and the
functional view comes out clearly if we compare them using a very
basic operation.

(defn dbl [a] (* 2 a))

Here we can inspect the code and convince ourselves that it does
indeed double its argument; we use deductive logic to do this.  So
when we use the function we do not need to "observe" anything; the
result just *is* what the application denotes.

But suppose we didn't have the source code; all we have is a black
box.  How would we know what it does?  We cannot use deductive logic,
since we cannot inspect the source; the best we can do is use
inductive logic: run a suitable selection of test cases through the
black box and draw an inference as to the meaning of its operation,
based on its behavior.  Here the key notion is _observation of
behavior_: we operate the black box and observe the resulting
behavior.  Note that ordinary function application does not involve
observation in this sense; _we_ can observe the result - the value of
the function - but this kind of observation is not explicitly
expressed by the code itself.  With interactional computation we make
it explicit:

[source,clojure]
----
;; hidden:
(def black-box (chan))
(go (while true (let [arg (<! black-box)] (>! black-box (dbl arg)))))
;; exposed:
(>!! black-box 2)
(let [result (<!! black-box)]
     (println "result: " result))
----

Here `(<!! black-box)` counts as making an observation; you can think
of `(>!! black-box 2)` as applying a stimulus.  Rather than "calling"
a "function" - we don't know if dbl is a function or not - we treat
this as performing a kind of behavioristic, Pavlovian experiment.

= co-routines

Another metaphor: throw an activation, catch an observation.  See the
chapter on co-routines in Lua manual: a yield far down in the call
stack of a resumed coroutine effectively "throws" control back to the
whatever called resume, but it's a boomerang throw, or a yo-yo, a throw with a
string attached so that the next resume will pick up the continuation
after yield.

Lua's co-routines are not really asymmetric; on the contrary, resume
and yield are perfectly symmetric.  Resume means co-yield, and yield
means co-resume.  Or more accurately, each means "yield here and
resume there".  But the natural language semantics of the words
obscures that fact; "yield" suggests only that the thread is
surrendering control, with no explicit indication as to where control
ought to resume.

We can think of every routine as having an implicit "current
continuation" variable.  Think of it in terms of instruction pointers.
We always have an IP pointing at the next instruction to execute; that
is, from the perspective of the routine, the "current" continuation.
But once execution of that instruction has begun, the cc becomes the
following instruction.  In other words, from the perspective of the
routine, the IP instruction is the cc; but from the perpective of the
IP instruction itself, the following instruction is the cc.  So we can
reify this as a "Continuation Pointer" to complement "instruction
Pointer", and just call it the cc.

Or maybe we don't need a CP; an IP is enough.  The IP always points at
the cc instruction.  So long as we stipulate that execution of the IP
instruction and incrementation of the IP go together this will work.
Or, we can keep one IP, but call it the current continuation
instruction pointer (CCIP)?  Parsed "current [continuation
instruction] pointer", counting every instruction as equivalent to a
continuation, a proxy for "the rest of the computation", i.e. the head
of a list of instructions rather than a single isolated instruction.
So the CCIP is to be thought of as pointing to the head of a list
rather than to a particular instruction.


Co-routines also implicitly retain (as part of their state), a
"co-CP", which is equal to the CP of the routine from which they were
resumed.  When they yield, they transfer control to that co-CP
instruction, which is in their co-routine.

So we can make all of the semantics quite explicit at a conceptual
level with a few simple reifications.

goblocks allow us to implement event-driven structures without
callbacks.  that's because gochannels act as intermediaries - we never
"call" co-functions directly, we only activate them.  We never observe
them directly either; what we observe is behavior, mediated via a
gochannel.

Co-functions oberve and behave.  To "call" a co-function is to behave
such that the co-function may observe the activation; to "return" is
to behave in such a manner that the co-function may observe the
result.

So observation and behavior always involve a pair of actions, one by
each party.  This gives us two options for each action: we can wait
for the co-function to execute the paired action, or we can move on
without waiting.  For example, when we activate a co-function, the
interaction is complete only when both actions complete - our
activation plus the co-function's observation of the activation.  With
standard, single-threaded functions, this is a monolithic, atomic
event: call the function, then wait for its result.  Multithreading
allows us to decouple these actions by using callbacks - call the
function, passing a callback, and then continue without waiting for
the function result.

When activating a co-function, we do not have the option of waiting
for the result; observation is a separate action.  But we do have the
option of waiting or not for the activation to be observed by the
co-function.  The situation is analogous to a communications protocol
where a sender may or may not wait for an ACK before proceeding with
its own work.

When observing, we have the option of waiting for the observation or
moving on and trying again later.

So we're really integrating several distinct concepts:

* model of computation: interactionist (activate/observe)

* code organization: threaded v. event-driven

* flow of control: coroutines (activate/observer) v. functions (call/return)

==== text is not process

==== concurrent v. parallel

Absurdities:

* link:https://en.wikipedia.org/wiki/Concurrent_computing[Wikipedia: Concurrent Computing]

"Concurrent computing is a form of computing in which several
computations are executing during overlapping time
periods—concurrently—instead of sequentially (one completing before
the next starts.)"

Anybody know what "overlapping time periods" means?  Didn't think so.

"concurrently - instead of sequentially (on completing before the next
starts)" - huh?  you mean simultaneously?  No?  Then what do you mean?
And how can one computation begin before another "completes"?  This is
just extraordinarily sloppy writing.  "Completes" apparently means
something special - e.g. done, the whole thing has finished and has
nothing more to do.  But preemption only ever happens when the
preempted process (text) has completed something - the primitive
operations are atomic, you cannot interrupt one in the middle, so to
speak.  So whatever the writer is trying to say, this kind of
"concurrency" has nothing to do with simultaneity - and so is not
really "concurrent" - and everything to do with sequence.  And nothing
to do with "time".

The absurdities continue: "concurrent computing consists of process
_lifetimes_ overlapping, but execution need not happen at the same
instant."  But what the hell is a "process lifetime", and how can time
every overlap?  "Process lifetime" clearly appeals to a notion of time
that is entirely distinct from the notion of computation, where "time"
means "step".  Clocktime, which is not relevant to the concept of
computation.

Part of the problem is the widespread conflation of "computation",
"process" and "program text".

So what does "concurrent computing" really mean?  Well, first off
let's be clear: "computing" here means "processing".  And so-called
concurrent processing is a rabidly stupid coinage if it is taken to
mean anything other than "simultaneous processing.

Then what should we call processing that involves preemptive switching
to another program text?  Note that I did not say "to another
thread". On a single cpu machine, there is only ever one "thread" but
there may be multiple texts, texts that may or may not be autonomous.

If the texts are truly autonomous - no joint dependencies - then we
don't need a special term.  The texts execute in sequence, and whether
or not they are interrupted to allow some other autonomous text to
execute is irrelevant - the meaning of the texts is not affected by
execution process.  Since texts are not processes, we should
definitely not call these "concurrent computations"; instead, we
should call them autonomous texts.  The process remains sequential
(single-threaded).  But there is another element, scheduling.  So we
have:

* autonomous texts
* single process
* preemptive scheduling (which means, another controlling process (meta-process?))

And preemptive scheduling might as well be random, from the
perspective of the texts and process.  Neither one cares when an
interrupt occurs; the end result will be the same.

This gives us the _illusion_ of simultaneity, but only due to the
speed of physical computers.

We can also have:

* autonomous texts

* single process

* non-preemptive scheduling - no controlling meta-process, texts (not
  processes) must cooperatively yield and resume

We really should discard "concurrent", or use it to mean what it means
etymologically, "simultaneolus", i.e. "parallel".

If not "concurrent", then what?  "Interruptible computing"?  Yuck.

Texts may be

* autonomous - no joint dependencies
* jointly dependent (e.g. on a global variable)
* mutually interdependent (each depends on the other)

This is about the _meaning_ of the text, and has nothing to do with
processing.

==== text; process; scheduling


= channels: the synchronous v. asynchronous fiction

More abominations:

link:https://en.wikipedia.org/wiki/Actor_model_and_process_calculi[Actor model and process calculii]

* "Synchronous channels have the property that a sender putting a
  message in the channel must wait for a receiver to get the message
  out of the channel before the sender can proceed."

* "Asynchronous channels have the property that a sender putting a
  message in the channel need not wait for a receiver to get the
  message out of the channel."

This kind of language is blatantly preposterous.  What does waiting
for a pick-up have to do with synchronicity that not waiting does not?
Either way, receipt happens after send.

The idea seems to be that synchronicity is a relation between sender
and receiver actions.  But waiting until something happens does not a
synchronicity make.  It's just an atrociously misplace metaphor.

Note that this sort of "chronicity" is a property of the _channel_.
Which should be enought right off the back to disqualify the
terminology - how can a channel be either synchronous or asynchronous?
Those are relations, not properties.

The classic metaphors: a phone call (on this model) would count as
involving a synchronous channel; a letter sent through the post office
would count as an asynchronous channel.  Or more precisely, the phone
network counts as a synchronous channel, the postal system as an
asychronous one.

But this is a ridiculous misuse of the English language.  Phone
conversations are not synchronous.  If both parties talk at once,
communication fails.  The key difference between the telephony
metaphor and the postal metaphor is the role of the intermediary.  Not
the fact of an intermediary; both systems involve an intermediary.

The phone system intermediary is not autonomous; the work it does
depends on the parties involved.  It only agrees to work as long as
the caller agrees; if the caller hangs up before the call is answered,
the intermediary quits too.  The postal intermediary, by contrast,
starts work when the sender posts a letter, and does not stop until it
is delivered, regardless of what the sender does after posting the
letter.  Furthermore it can sit on the letter for an arbitrarily long
period.  And finally it only has to deliver the letter; it does not
have to stick around to see if the addressee actually opens the
letter.

Placing a phone call does not count as making a phone call if nobody
picks up.  So the _act_ of calling somebody is dependent on pick-up.

In any case it is clearly an abuse of the language to introduce
notions of synchronicity.

  What does it have to
do with synchonicity (temporality)?

What it's really about is mediation.  "Synchronous" channels are
unmediated; "asynchronous" channels are mediated.  That's it.  Nothing
to do with synchronicity.

Better: mediated v. non-mediated channel.  The fiction is that
communication across a non-mediated channel is direct and
instantaneous - entanglement.  In fact there may be a delay, but in
principle, when you dial somebody they pick up instantly.  Waiting for
them to pick up is an implementation detail, so to speak - an evil
necessary to sustain the illusion.

BUT: the key point is not the reponse from the other end, but only the
pickup.  Note the ambiguity of "answer" - in talk, one answers by
saying something in reponse, but on the telephony system, one answers
by just picking up the phone.  Actually saying "hello" is part of a
higher-level protocol.  So when we make a call and wait, what we're
waiting for is the pickup, not the "hello".

Immediate channel: in principle, direct, "instantaneous" reponse; in
practice, a gap between call (activation) and response (observation).

Mediated channel: same, really, except no wait in case of gap.

So how to characterize this "wait for pickup" if not as synchronicity?
Definition of "act"?  With immediate channel, activation (calling) is
not complete until partner acknowledges (receives message).  With
mediated channel, activation is complete as soon as it is made,
without regard to ack.

Compare: connection-oriented protocol v. non-connection-oriented (tcb
v. udp).  Then a "synchronous channel" is one that implements a
connection-oriented protocol.

So we add protocol to our stock of primitives:

* texts (autonomous v. jointly dependent v. mutually dependent)

* control  (single v. multiple processes)

* scheduling (preemptive v. non-preemptive) (meta-process)

* protocol (mediated v. non-mediated, or direct v. indirect)

Then instead of e.g. "synchronous channel" we have "non-mediated
protocol", and the latter is atemporal.

Non-mediated protocol: action cannot be completed without cooperation
of both parties (i.e. callee picks up).  So instead of "non-mediated",
maybe "cooperative"?  "direct"?  Compare legal: process server -
subpoena must be delivered in person and acknowledged.

Real-world analogs not involving communication:

"asynchronous", no-waiting:

* washer-dryer: you put the clothes in and then go about your business
  until later - you don't stand there waiting for the machines to
  finish

* cooking: you put the meatloaf in the oven and come back later; you
  don't stand there watching it cook

* web surfing - click on a link, and often you wait for the page to
  load.  of course you don't have to - you can switch to something
  else and then come back - but we all want our pages to load
  instantaneously.

Almost everything we do counts as "asynchronous" in this sense.

"synchronous", waiting - for this, we want examples where we may
expect immediate response, but will wait if necessary; or, better,
where continuation w/o response is not possible.  that probaly almost
never happens - we can always go do something else.

* ringing a doorbell

* conversation - you don't ask a question and then go do something
  else, you expect an immediate response, which presupposes that the
  other party receives your message "synchronously" - as soon as it
  leaves your mouth.  this may be the paradigm of "synchronous"
  communication.  it involves both synchronicity of send/receive
  interaction, and sequential turn-taking.

* handshaking - you cannot extend you hand and then leave it hanging
  in midair while you go do something else; you have to wait until the
  other guy grabs your hand

* passing the salt - if you pass it hand-to-hand, you have to wait for
  the receiver to take it from your hand.  if you slide it across the
  table, you don't have to wait

* reading a book - when you turn the page, you expect to start reading
  without delay - you don't go make a cup of coffee while you wait for
  the text to appear on the page

* turning on/off a light - we expect immediate results; unless you
  have one of those crappy new bulbs that take forever to light up,
  you don't flip the switch, go do something else, and then come back
  later

* feeding - you wait to make sure your kid eats; for your pets, you
  put down food and don't wait around to make sure they eat it
  immediately

* hot water - you want hot water from your faucets immediately, but if
  it takes a while to warm up, you'll probably wait.  if it takes too
  long you might go do something else and then come back and check it

* computer logon - you cannot continue (with the computer) if your
  logon fails so if it's a little slow you must wait.  although, here
  too, you can go make a cup of coffee while windows boots up.

* going to the bathroom - you really can't do much else until you're
  done

* phone calls - you have to wait for the other party to pick up.
  unless you have a speaker phone; then you can let it ring in the
  background while you do other things.  compare being put on hold
  when you call the help line.

moral: wherever delay is _possible_ we have "asynch" - you can always
go do something else while waiting.  but that's because we're people -
machines are different.

So it's not about the channel, its about the protocol: do activations
wait around to be observed or not?

But then, how does the activation "know" it has been observed?  There
would have to be a feedback loop involving another channel.

The central fiction is entanglement: activation and observation are
co-equal.  Every call is ipso facto observed.  This is not
simultaneity, though, since entanglement is atemporal; but in practice
this co-equality can only be represented as simultaneity.  And since
simultaneity is hard (impossible) to do, there will always in practice
be a delay between activation and observation, and so we have the
option of sustaining the fiction in two ways: using a "blocking
activation", which emulates simultaneity by treating
activation/observation as an atomic unit no matter how long the delay;
and "asynchronous activation", which sustains the fiction by assuming
that activations are instantly observed (even if there is a delay on
the receiving end) and moving the delay on the caller's side to the
observation channel.

Such "asynchronous activation" can be implemented using either threads
or callbacks.  Either way, "asynchronous" is not very descriptive; it
should be called just non-blocking or instant or something similar.
The practical question for the caller is how and where to deal with
possible delays.  There are several strategies:

1.  blocking activation - put the wait at the beginning

2.  blocking observation - treat the call as ipso facto observed, wait
for response.  any delay in the receiver's acceptance of the call
appears to the caller as delay in response.

3.  block chopping, aka polling.  never block - the observation call
always returns immediately with success or failure - but keep
observing until an observation succeeds.  here an observation call
that would block for n seconds is chopped into m non-blocking calls.
But "non-blocking call" is a fiction; since every call in practice
takes a non-zero amount of time, the best we can do is have "micro
blocking calls", calls that return very rapidly if no observation is
ready.  So what we really have is one fat blocking call chopped into a
bunch of micro blocking calls.  If you make 10K micro-blocking calls
before observing a datum, and that takes n seconds, it's equivalent to
an n second blocking call, except that chopping it into micro-blocking
calls allows us to interleave useful work and therefore create the
illusion of non-blocking.  this will involve a loop, which can have
the drawback of chewing cycles if the loop is tight.  you never block
on the observation call, but you may burn a lot of cycles just
looping.  and if you don't do this right you effectively block
totally, nothing else gets done.  so you shift delay from a blocking
call to a spinning loop.  on the other hand, if you design it right
this technique can be very efficient.  for example you can use
coroutines to check regularly for observations but continue on with
work if nothing available yet.

note that block chopping need not involve a large number of
micro-blocking calls.  if the delay is n seconds, and we have n
seconds worth of other work to do, our loop may make only a few
micro-blocking observation calls.  in this case the sum of time
working plus time in micro blocking calls equals delay time.  so we're
really managing both blocking observation and work-while-waiting.

4.  callbacks - treat the call as ipso facto observed as with strategy
2; but instead of making a blocking observation, or polling with a
non-blocking observation, register an observation callback.  this
effectively moves the observational duties to the channel or runtime,
which will invoke the callback when _it_ makes an observation.  The
callback still waits around to be invoked, but it doesn't block, since
it does not run until called.  A form of passive action - call it
passive polling?  with this strategy there is no observation loop,
because you never actually make an observation call - you delegate
that responsibility to whatever manages the callback.  this strategy
effectively involves blocking on an implicit background thread, one
managed by the runtime or the channel or whatever is responsible for
managing callbacks.

5.  threads - go ahead and block, just do it on a background thread.
now you don't need polling or callbacks to enable work-while-waiting,
since a blocking observation on a bg thread does not block other
threads.  here the problem is communication among threads.

Call these "blocking strategies"?  Meaning, strategies for dealing
with delays that under naive model would result in blocking.  Blocking
_always_ occurs when there is a delay; these strategies address
different ways of blocking.  And really they're about what we do while
waiting: either block, or work on something else.  Plus how we know
that waiting is over (observation call v. callback)


== threads v. co-threads

co-routines are often called lightweight threads (or similar), since
they are similar to OS threads, but they differ in that they are not
preemptively scheduled by the OS.

how is this sort of threading related to the issues discussed here, namely

* model of computation: interactionist (activate/observe) v. sequential (call/return)

* code organization: threaded v. event-driven

* flow of control: coroutines (activate/observe) v. subroutines (fns) (call/return) v. threads

* "entanglement" management: blocking, polling, callbacks, threads

* threads v. co-threads  (same as flow of control?)


entanglement fiction == ipso-facto interactionism


=== implementation

defcofn: use protocol and type

defprotocol declares ops activate and observe

deftype CoFunction keeps two channels, in and out, with some alias for
convenience, so user can e.g. define cofn "home" and then do (activate
home ...) and (observe home).  Each returns the cofn so these can be
chained: (observe (activate home)).  The protocol implementation maps
"home" in each case to the appropriate channel.

defcofn takes an implementation body as well, and sets up the gochans
and goblocks necessary to make activate/observe work.  Blocking
strategy expressed via the usual ! decoration.

=== pavlovian entanglement

pavlovian: behavior/observation

entanglement: hidden mechanism, "simultaneity", behavior and
observation joint aspects of one system

alternative:  interaction structure

We can model a PE as system consisting of a pair of connected
(entangled) state machines.